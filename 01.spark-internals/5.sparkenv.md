# 5.sparkenv

## 5.1 上下文

在 `SparkContext` 初始化的时候，涉及 `SparkEnv` 的有如下代码。

```scala
// ${SPARK_HOME}/core/src/main/scala/org/apache/spark/SparkContext.scala

class SparkContext(config: SparkConf) extends Logging {
    // Create the Spark execution environment (cache, map output tracker, etc)
    _env = createSparkEnv(_conf, isLocal, listenerBus)
    SparkEnv.set(_env)
    
    // If running the REPL, register the repl's output dir with the file server.
    _conf.getOption("spark.repl.class.outputDir").foreach { path =>
        val replUri = _env.rpcEnv.fileServer.addDirectory("/classes", new File(path))
        _conf.set("spark.repl.class.uri", replUri)
    }
    
    _ui =
        if (conf.getBoolean("spark.ui.enabled", true)) {
            Some(SparkUI.createLiveUI(this, _conf, listenerBus, _jobProgressListener,
                _env.securityManager, appName, startTime = startTime))
        } else {
            // For tests, do not enable the UI
            None
        }
        
    _env.blockManager.initialize(_applicationId)
    
    // The metrics system for Driver need to be set spark.app.id to app ID.
    // So it should start after we get app ID from the task scheduler and set spark.app.id.
    _env.metricsSystem.start()
    // Attach the driver metrics servlet handler to the web ui after the metrics system is started.
    _env.metricsSystem.getServletHandlers.foreach(handler => ui.foreach(_.attachHandler(handler)))
    
    _env.metricsSystem.registerSource(_dagScheduler.metricsSource)
    _env.metricsSystem.registerSource(new BlockManagerSource(_env.blockManager))
    _executorAllocationManager.foreach { e =>
        _env.metricsSystem.registerSource(e.executorAllocationManagerSource)
    }
}
```

